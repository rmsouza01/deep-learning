{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Approaches to Defining Neural Networks with Keras and TensorFlow\n",
    "\n",
    "[TensorFlow](https://www.tensorflow.org/) 2.0 came with many new exciting updates. One of these updates was full integration with the very popular [Keras API](https://keras.io/) for developing deep learning models. Before TensorFlow 2.0, you had two install TensorfFlow and Keras separately. Now, Keras comes as a submodule of TensorFlow (*i.e.*, tensorflow.keras). We will be using Keras and TensorFlow on the majority of tutorials in this class. There are 3 ways to define Neural Networks with Keras. In this tutorial we will cover these different ways.\n",
    "\n",
    "The learning goals of this tutorial are:\n",
    "    - Introduce the Keras sequential API, functional API and model subclassing methods for defining neural networks;\n",
    "    - Illustrate a simple classiifcation problem using the Iris dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Libraries \n",
    "\n",
    "If you get an error that a library is not installed, most libraries you can stall on a jupyter notebook by creating a new cell and typing:\n",
    "\n",
    "- *! pip install library_name*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # Function to convert labels to one-hot encoding\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.datasets import load_iris  # Function for loading the Iris dataset\n",
    "from sklearn.model_selection import train_test_split # Function for splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and return to the defined variable \n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data into a DataFrame\n",
    "dframe = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "# add \"target_label\" column to the dataset and name it \"label\"\n",
    "dframe['labels'] = dataset.target.astype(int) # Labels are represented as integers\n",
    "# use of String label\n",
    "dframe['label_names'] = dframe.labels.replace(dict(enumerate(dataset.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   labels label_names  \n",
       "0       0      setosa  \n",
       "1       0      setosa  \n",
       "2       0      setosa  \n",
       "3       0      setosa  \n",
       "4       0      setosa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the 5 first rows/samples of the dataset\n",
    "dframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      labels  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates a short description of the dataset (missing values, mean values, etc.)\n",
    "dframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation and Test Sets Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the features and labels from the dataset \n",
    "X = np.asarray(dframe[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "Y = np.asarray(dframe['labels'])\n",
    "\n",
    "# First we will shuffle the samples\n",
    "indexes = np.arange(X.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "X = X[indexes,:]\n",
    "Y = Y[indexes]\n",
    "\n",
    "# Then, we split our data into train/val/test sets\n",
    "train_split = np.int(0.5*Y.size)\n",
    "val_split = np.int(0.75*Y.size)\n",
    "\n",
    "X_train = X[:train_split,:]\n",
    "Y_train = Y[:train_split]\n",
    "\n",
    "X_val = X[train_split:val_split,:]\n",
    "Y_val = Y[train_split:val_split]\n",
    "\n",
    "X_test = X[val_split:,:]\n",
    "Y_test = Y[val_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max data normalization\n",
    "x_train_min = X_train.min(axis = 0, keepdims = True)\n",
    "x_train_max = X_train.max(axis = 0, keepdims = True)\n",
    "\n",
    "X_train = (X_train - x_train_min)/(x_train_max - x_train_min)\n",
    "X_val = (X_val - x_train_min)/(x_train_max - x_train_min)\n",
    "X_test = (X_test - x_train_min)/(x_train_max - x_train_min)\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#Activity suggestion:\n",
    "# 1. Change the min-max normalization above by standardization ((X - mean)/(std))\n",
    "# 2. Don't normalize the data and see what happens\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Labels using one-hot-ecoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train[:5]:\n",
      "[0 2 0 2 1]\n",
      "\n",
      "Y_oh_train[:5]=\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "k = np.unique(Y).size\n",
    "Y_oh_train = to_categorical(Y_train, k) \n",
    "Y_oh_val = to_categorical(Y_val, k) \n",
    "Y_oh_test = to_categorical(Y_test, k)\n",
    "# Displaying the 5 first elemnts\n",
    "print('Y_train[:5]:')\n",
    "print(Y_train[:5])\n",
    "print('\\nY_oh_train[:5]=')\n",
    "print(Y_oh_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train :  (75, 4)\n",
      "Size of X_val :  (37, 4)\n",
      "Size of X_test :  (38, 4)\n"
     ]
    }
   ],
   "source": [
    "print( \"Size of X_train : \" , X_train.shape)\n",
    "print( \"Size of X_val : \" , X_val.shape)\n",
    "print( \"Size of X_test : \" , X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Approaches for Defining Neural Networks\n",
    "\n",
    "### 1. The Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "# Passing a list of layers to the constructor\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(5, activation='relu', input_shape=(4,) , name = \"layer1\"),\n",
    "    tf.keras.layers.Dense(10, activation='relu' , name = \"layer2\"),\n",
    "    tf.keras.layers.Dense(3, activation='softmax', name = \"layer3\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "# This returns a tensor\n",
    "input_tensor = tf.keras.layers.Input(shape=(4,))\n",
    "# A layer instance is callable on a tensor, and returns a tensor\n",
    "x1 = tf.keras.layers.Dense(5, activation='relu')(input_tensor)\n",
    "x2 = tf.keras.layers.Dense(10, activation='relu')(x1)\n",
    "out_tensor = tf.keras.layers.Dense(3, activation='softmax')(x2)\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=input_tensor, outputs=out_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  25        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  60        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyNeuralNetwork(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyNeuralNetwork, self).__init__(**kwargs)\n",
    "        self.dense1 = tf.keras.layers.Dense(5, activation='relu', )\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(3, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x1 = self.dense1(inputs)\n",
    "        x2 = self.dense2(x1)\n",
    "        out_tensor = self.dense3(x2)\n",
    "        return out_tensor\n",
    "model = MyNeuralNetwork()\n",
    "model.build(input_shape = (None,4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) # compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7202 - accuracy: 0.7467 - val_loss: 0.6983 - val_accuracy: 0.7568\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7157 - accuracy: 0.7467 - val_loss: 0.6942 - val_accuracy: 0.7568\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7111 - accuracy: 0.7467 - val_loss: 0.6905 - val_accuracy: 0.7838\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.7065 - accuracy: 0.7600 - val_loss: 0.6869 - val_accuracy: 0.7838\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7019 - accuracy: 0.7600 - val_loss: 0.6834 - val_accuracy: 0.8378\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6974 - accuracy: 0.7600 - val_loss: 0.6798 - val_accuracy: 0.8378\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6929 - accuracy: 0.7733 - val_loss: 0.6761 - val_accuracy: 0.8378\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6884 - accuracy: 0.7733 - val_loss: 0.6722 - val_accuracy: 0.8378\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6841 - accuracy: 0.7733 - val_loss: 0.6684 - val_accuracy: 0.8378\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6798 - accuracy: 0.7733 - val_loss: 0.6649 - val_accuracy: 0.8378\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.7867 - val_loss: 0.6616 - val_accuracy: 0.8378\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6711 - accuracy: 0.7867 - val_loss: 0.6580 - val_accuracy: 0.8378\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6668 - accuracy: 0.7867 - val_loss: 0.6541 - val_accuracy: 0.8378\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6624 - accuracy: 0.8000 - val_loss: 0.6501 - val_accuracy: 0.8378\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6581 - accuracy: 0.8000 - val_loss: 0.6458 - val_accuracy: 0.8378\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6540 - accuracy: 0.8000 - val_loss: 0.6416 - val_accuracy: 0.8378\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6498 - accuracy: 0.8000 - val_loss: 0.6376 - val_accuracy: 0.8378\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.8000 - val_loss: 0.6339 - val_accuracy: 0.8378\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6414 - accuracy: 0.8000 - val_loss: 0.6306 - val_accuracy: 0.8378\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6371 - accuracy: 0.8000 - val_loss: 0.6277 - val_accuracy: 0.8649\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6328 - accuracy: 0.8000 - val_loss: 0.6253 - val_accuracy: 0.8649\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6285 - accuracy: 0.8000 - val_loss: 0.6232 - val_accuracy: 0.8649\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6247 - accuracy: 0.8267 - val_loss: 0.6206 - val_accuracy: 0.8649\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6202 - accuracy: 0.8267 - val_loss: 0.6173 - val_accuracy: 0.8919\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6162 - accuracy: 0.8267 - val_loss: 0.6143 - val_accuracy: 0.9189\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6121 - accuracy: 0.8400 - val_loss: 0.6116 - val_accuracy: 0.9189\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6081 - accuracy: 0.8533 - val_loss: 0.6093 - val_accuracy: 0.9189\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6047 - accuracy: 0.8667 - val_loss: 0.6068 - val_accuracy: 0.9189\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6004 - accuracy: 0.8667 - val_loss: 0.6031 - val_accuracy: 0.9189\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5965 - accuracy: 0.8667 - val_loss: 0.5989 - val_accuracy: 0.9189\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5928 - accuracy: 0.8667 - val_loss: 0.5948 - val_accuracy: 0.9189\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5891 - accuracy: 0.8667 - val_loss: 0.5912 - val_accuracy: 0.9189\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5854 - accuracy: 0.8667 - val_loss: 0.5879 - val_accuracy: 0.9189\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5818 - accuracy: 0.8667 - val_loss: 0.5844 - val_accuracy: 0.9189\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5781 - accuracy: 0.8667 - val_loss: 0.5810 - val_accuracy: 0.9189\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5744 - accuracy: 0.8667 - val_loss: 0.5773 - val_accuracy: 0.9189\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5708 - accuracy: 0.8667 - val_loss: 0.5738 - val_accuracy: 0.9189\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5672 - accuracy: 0.8667 - val_loss: 0.5708 - val_accuracy: 0.9189\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5635 - accuracy: 0.8667 - val_loss: 0.5681 - val_accuracy: 0.9189\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5599 - accuracy: 0.8800 - val_loss: 0.5656 - val_accuracy: 0.9189\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5563 - accuracy: 0.8800 - val_loss: 0.5633 - val_accuracy: 0.9189\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5528 - accuracy: 0.8800 - val_loss: 0.5610 - val_accuracy: 0.9189\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5492 - accuracy: 0.8800 - val_loss: 0.5589 - val_accuracy: 0.9189\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5459 - accuracy: 0.9200 - val_loss: 0.5564 - val_accuracy: 0.9189\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5422 - accuracy: 0.9200 - val_loss: 0.5534 - val_accuracy: 0.9189\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5387 - accuracy: 0.9200 - val_loss: 0.5503 - val_accuracy: 0.9189\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5352 - accuracy: 0.9200 - val_loss: 0.5468 - val_accuracy: 0.9189\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5317 - accuracy: 0.9067 - val_loss: 0.5430 - val_accuracy: 0.9189\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5286 - accuracy: 0.8800 - val_loss: 0.5395 - val_accuracy: 0.9189\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5251 - accuracy: 0.8800 - val_loss: 0.5369 - val_accuracy: 0.9189\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5218 - accuracy: 0.8800 - val_loss: 0.5342 - val_accuracy: 0.9189\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5184 - accuracy: 0.8933 - val_loss: 0.5313 - val_accuracy: 0.9189\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5151 - accuracy: 0.8933 - val_loss: 0.5281 - val_accuracy: 0.9189\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5119 - accuracy: 0.8933 - val_loss: 0.5249 - val_accuracy: 0.9189\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5087 - accuracy: 0.8800 - val_loss: 0.5214 - val_accuracy: 0.9189\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5056 - accuracy: 0.8800 - val_loss: 0.5180 - val_accuracy: 0.9189\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5026 - accuracy: 0.8800 - val_loss: 0.5150 - val_accuracy: 0.9189\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4995 - accuracy: 0.8800 - val_loss: 0.5125 - val_accuracy: 0.9189\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4964 - accuracy: 0.8933 - val_loss: 0.5105 - val_accuracy: 0.9189\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4934 - accuracy: 0.9067 - val_loss: 0.5084 - val_accuracy: 0.9189\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4903 - accuracy: 0.9200 - val_loss: 0.5063 - val_accuracy: 0.9189\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4872 - accuracy: 0.9333 - val_loss: 0.5047 - val_accuracy: 0.9189\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4843 - accuracy: 0.9333 - val_loss: 0.5036 - val_accuracy: 0.9189\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4815 - accuracy: 0.9467 - val_loss: 0.5020 - val_accuracy: 0.9459\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4785 - accuracy: 0.9467 - val_loss: 0.4995 - val_accuracy: 0.9459\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4755 - accuracy: 0.9467 - val_loss: 0.4966 - val_accuracy: 0.9459\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.9467 - val_loss: 0.4935 - val_accuracy: 0.9459\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4697 - accuracy: 0.9467 - val_loss: 0.4910 - val_accuracy: 0.9459\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4668 - accuracy: 0.9467 - val_loss: 0.4888 - val_accuracy: 0.9730\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.9467 - val_loss: 0.4869 - val_accuracy: 0.9730\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4612 - accuracy: 0.9467 - val_loss: 0.4853 - val_accuracy: 0.9730\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4583 - accuracy: 0.9467 - val_loss: 0.4828 - val_accuracy: 0.9730\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4554 - accuracy: 0.9467 - val_loss: 0.4801 - val_accuracy: 0.9730\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4526 - accuracy: 0.9467 - val_loss: 0.4776 - val_accuracy: 0.9730\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4498 - accuracy: 0.9467 - val_loss: 0.4757 - val_accuracy: 0.9730\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4471 - accuracy: 0.9467 - val_loss: 0.4741 - val_accuracy: 0.9730\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4443 - accuracy: 0.9467 - val_loss: 0.4722 - val_accuracy: 0.9730\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.9467 - val_loss: 0.4704 - val_accuracy: 0.9730\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4389 - accuracy: 0.9467 - val_loss: 0.4687 - val_accuracy: 0.9730\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4362 - accuracy: 0.9467 - val_loss: 0.4668 - val_accuracy: 0.9730\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4335 - accuracy: 0.9467 - val_loss: 0.4640 - val_accuracy: 0.9730\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4309 - accuracy: 0.9467 - val_loss: 0.4607 - val_accuracy: 0.9730\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4281 - accuracy: 0.9467 - val_loss: 0.4576 - val_accuracy: 0.9730\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4254 - accuracy: 0.9467 - val_loss: 0.4541 - val_accuracy: 0.9730\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4229 - accuracy: 0.9467 - val_loss: 0.4506 - val_accuracy: 0.9730\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.9467 - val_loss: 0.4471 - val_accuracy: 0.9730\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4180 - accuracy: 0.9467 - val_loss: 0.4437 - val_accuracy: 0.9730\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.9467 - val_loss: 0.4413 - val_accuracy: 0.9730\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4132 - accuracy: 0.9467 - val_loss: 0.4400 - val_accuracy: 0.9730\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.9467 - val_loss: 0.4397 - val_accuracy: 0.9730\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.9600 - val_loss: 0.4396 - val_accuracy: 0.9730\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4054 - accuracy: 0.9467 - val_loss: 0.4387 - val_accuracy: 0.9730\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4030 - accuracy: 0.9467 - val_loss: 0.4367 - val_accuracy: 0.9730\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4006 - accuracy: 0.9467 - val_loss: 0.4337 - val_accuracy: 0.9730\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3982 - accuracy: 0.9467 - val_loss: 0.4307 - val_accuracy: 0.9730\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.9467 - val_loss: 0.4281 - val_accuracy: 0.9730\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3935 - accuracy: 0.9467 - val_loss: 0.4262 - val_accuracy: 0.9730\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3910 - accuracy: 0.9467 - val_loss: 0.4253 - val_accuracy: 0.9730\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3886 - accuracy: 0.9467 - val_loss: 0.4248 - val_accuracy: 0.9730\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3863 - accuracy: 0.9467 - val_loss: 0.4242 - val_accuracy: 0.9730\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3841 - accuracy: 0.9333 - val_loss: 0.4234 - val_accuracy: 0.9730\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3820 - accuracy: 0.9467 - val_loss: 0.4220 - val_accuracy: 0.9730\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3796 - accuracy: 0.9467 - val_loss: 0.4190 - val_accuracy: 0.9730\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.9467 - val_loss: 0.4161 - val_accuracy: 0.9730\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3748 - accuracy: 0.9467 - val_loss: 0.4143 - val_accuracy: 0.9730\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3726 - accuracy: 0.9467 - val_loss: 0.4119 - val_accuracy: 0.9730\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3703 - accuracy: 0.9467 - val_loss: 0.4092 - val_accuracy: 0.9730\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.9467 - val_loss: 0.4076 - val_accuracy: 0.9730\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3659 - accuracy: 0.9467 - val_loss: 0.4058 - val_accuracy: 0.9730\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3635 - accuracy: 0.9467 - val_loss: 0.4031 - val_accuracy: 0.9730\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3613 - accuracy: 0.9467 - val_loss: 0.3994 - val_accuracy: 0.9730\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3590 - accuracy: 0.9600 - val_loss: 0.3948 - val_accuracy: 0.9730\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3575 - accuracy: 0.9467 - val_loss: 0.3908 - val_accuracy: 0.9730\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3559 - accuracy: 0.9600 - val_loss: 0.3879 - val_accuracy: 0.9730\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3542 - accuracy: 0.9600 - val_loss: 0.3854 - val_accuracy: 0.9730\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3524 - accuracy: 0.9600 - val_loss: 0.3837 - val_accuracy: 0.9730\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.9600 - val_loss: 0.3826 - val_accuracy: 0.9730\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3480 - accuracy: 0.9600 - val_loss: 0.3812 - val_accuracy: 0.9730\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3456 - accuracy: 0.9600 - val_loss: 0.3791 - val_accuracy: 0.9730\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.9600 - val_loss: 0.3771 - val_accuracy: 0.9730\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3420 - accuracy: 0.9600 - val_loss: 0.3756 - val_accuracy: 0.9730\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3399 - accuracy: 0.9600 - val_loss: 0.3750 - val_accuracy: 0.9730\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3378 - accuracy: 0.9600 - val_loss: 0.3750 - val_accuracy: 0.9730\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3355 - accuracy: 0.9600 - val_loss: 0.3750 - val_accuracy: 0.9730\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3334 - accuracy: 0.9600 - val_loss: 0.3753 - val_accuracy: 0.9730\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.9467 - val_loss: 0.3756 - val_accuracy: 0.9730\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3294 - accuracy: 0.9467 - val_loss: 0.3762 - val_accuracy: 0.9459\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3277 - accuracy: 0.9467 - val_loss: 0.3776 - val_accuracy: 0.9459\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.9467 - val_loss: 0.3777 - val_accuracy: 0.9459\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.9467 - val_loss: 0.3765 - val_accuracy: 0.9459\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.9467 - val_loss: 0.3750 - val_accuracy: 0.9459\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3206 - accuracy: 0.9467 - val_loss: 0.3714 - val_accuracy: 0.9459\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3184 - accuracy: 0.9467 - val_loss: 0.3663 - val_accuracy: 0.9459\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.9467 - val_loss: 0.3622 - val_accuracy: 0.9459\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3138 - accuracy: 0.9467 - val_loss: 0.3585 - val_accuracy: 0.9730\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3121 - accuracy: 0.9467 - val_loss: 0.3554 - val_accuracy: 0.9730\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3103 - accuracy: 0.9467 - val_loss: 0.3530 - val_accuracy: 0.9730\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.9467 - val_loss: 0.3508 - val_accuracy: 0.9730\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3067 - accuracy: 0.9467 - val_loss: 0.3482 - val_accuracy: 0.9730\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3050 - accuracy: 0.9600 - val_loss: 0.3452 - val_accuracy: 0.9730\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3037 - accuracy: 0.9600 - val_loss: 0.3428 - val_accuracy: 0.9730\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3022 - accuracy: 0.9600 - val_loss: 0.3410 - val_accuracy: 0.9730\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3005 - accuracy: 0.9600 - val_loss: 0.3395 - val_accuracy: 0.9730\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2988 - accuracy: 0.9600 - val_loss: 0.3385 - val_accuracy: 0.9730\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2969 - accuracy: 0.9600 - val_loss: 0.3382 - val_accuracy: 0.9730\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2947 - accuracy: 0.9600 - val_loss: 0.3388 - val_accuracy: 0.9730\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2927 - accuracy: 0.9467 - val_loss: 0.3400 - val_accuracy: 0.9459\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2905 - accuracy: 0.9467 - val_loss: 0.3409 - val_accuracy: 0.9459\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2885 - accuracy: 0.9467 - val_loss: 0.3419 - val_accuracy: 0.9459\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2869 - accuracy: 0.9467 - val_loss: 0.3423 - val_accuracy: 0.9459\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2852 - accuracy: 0.9467 - val_loss: 0.3415 - val_accuracy: 0.9459\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2833 - accuracy: 0.9467 - val_loss: 0.3402 - val_accuracy: 0.9459\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2816 - accuracy: 0.9467 - val_loss: 0.3377 - val_accuracy: 0.9459\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2796 - accuracy: 0.9467 - val_loss: 0.3339 - val_accuracy: 0.9459\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2779 - accuracy: 0.9467 - val_loss: 0.3307 - val_accuracy: 0.9459\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2760 - accuracy: 0.9467 - val_loss: 0.3282 - val_accuracy: 0.9459\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2745 - accuracy: 0.9467 - val_loss: 0.3263 - val_accuracy: 0.9459\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2727 - accuracy: 0.9467 - val_loss: 0.3256 - val_accuracy: 0.9459\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2710 - accuracy: 0.9467 - val_loss: 0.3246 - val_accuracy: 0.9459\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2693 - accuracy: 0.9467 - val_loss: 0.3231 - val_accuracy: 0.9459\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2678 - accuracy: 0.9467 - val_loss: 0.3227 - val_accuracy: 0.9459\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2661 - accuracy: 0.9467 - val_loss: 0.3233 - val_accuracy: 0.9459\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - accuracy: 0.9467 - val_loss: 0.3218 - val_accuracy: 0.9459\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2626 - accuracy: 0.9467 - val_loss: 0.3181 - val_accuracy: 0.9459\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2616 - accuracy: 0.9467 - val_loss: 0.3158 - val_accuracy: 0.9459\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2595 - accuracy: 0.9467 - val_loss: 0.3167 - val_accuracy: 0.9459\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2582 - accuracy: 0.9467 - val_loss: 0.3174 - val_accuracy: 0.9459\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2564 - accuracy: 0.9467 - val_loss: 0.3173 - val_accuracy: 0.9459\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2549 - accuracy: 0.9467 - val_loss: 0.3183 - val_accuracy: 0.9459\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2537 - accuracy: 0.9467 - val_loss: 0.3187 - val_accuracy: 0.9459\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2523 - accuracy: 0.9467 - val_loss: 0.3196 - val_accuracy: 0.9189\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2512 - accuracy: 0.9600 - val_loss: 0.3212 - val_accuracy: 0.9189\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2501 - accuracy: 0.9600 - val_loss: 0.3214 - val_accuracy: 0.8919\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2489 - accuracy: 0.9600 - val_loss: 0.3198 - val_accuracy: 0.8919\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2473 - accuracy: 0.9600 - val_loss: 0.3158 - val_accuracy: 0.9189\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2453 - accuracy: 0.9600 - val_loss: 0.3097 - val_accuracy: 0.9459\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2437 - accuracy: 0.9467 - val_loss: 0.3035 - val_accuracy: 0.9459\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2421 - accuracy: 0.9467 - val_loss: 0.2994 - val_accuracy: 0.9459\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2407 - accuracy: 0.9467 - val_loss: 0.2965 - val_accuracy: 0.9459\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2397 - accuracy: 0.9467 - val_loss: 0.2957 - val_accuracy: 0.9459\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2384 - accuracy: 0.9467 - val_loss: 0.2959 - val_accuracy: 0.9459\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2367 - accuracy: 0.9467 - val_loss: 0.2940 - val_accuracy: 0.9459\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2355 - accuracy: 0.9467 - val_loss: 0.2916 - val_accuracy: 0.9459\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9467 - val_loss: 0.2912 - val_accuracy: 0.9459\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2330 - accuracy: 0.9467 - val_loss: 0.2914 - val_accuracy: 0.9459\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2316 - accuracy: 0.9467 - val_loss: 0.2898 - val_accuracy: 0.9459\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2302 - accuracy: 0.9467 - val_loss: 0.2870 - val_accuracy: 0.9459\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2292 - accuracy: 0.9467 - val_loss: 0.2842 - val_accuracy: 0.9459\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.9467 - val_loss: 0.2815 - val_accuracy: 0.9459\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2273 - accuracy: 0.9467 - val_loss: 0.2785 - val_accuracy: 0.9459\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2266 - accuracy: 0.9467 - val_loss: 0.2759 - val_accuracy: 0.9730\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2260 - accuracy: 0.9467 - val_loss: 0.2744 - val_accuracy: 0.9730\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2249 - accuracy: 0.9467 - val_loss: 0.2742 - val_accuracy: 0.9730\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2234 - accuracy: 0.9467 - val_loss: 0.2749 - val_accuracy: 0.9459\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2217 - accuracy: 0.9467 - val_loss: 0.2757 - val_accuracy: 0.9459\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2201 - accuracy: 0.9467 - val_loss: 0.2763 - val_accuracy: 0.9459\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2185 - accuracy: 0.9467 - val_loss: 0.2767 - val_accuracy: 0.9459\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2170 - accuracy: 0.9467 - val_loss: 0.2783 - val_accuracy: 0.9459\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2159 - accuracy: 0.9467 - val_loss: 0.2801 - val_accuracy: 0.9459\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9467 - val_loss: 0.2803 - val_accuracy: 0.9459\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2134 - accuracy: 0.9467 - val_loss: 0.2804 - val_accuracy: 0.9459\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2122 - accuracy: 0.9467 - val_loss: 0.2816 - val_accuracy: 0.9189\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2110 - accuracy: 0.9467 - val_loss: 0.2831 - val_accuracy: 0.9189\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2102 - accuracy: 0.9467 - val_loss: 0.2846 - val_accuracy: 0.9189\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2093 - accuracy: 0.9600 - val_loss: 0.2839 - val_accuracy: 0.9189\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2080 - accuracy: 0.9600 - val_loss: 0.2809 - val_accuracy: 0.9189\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2066 - accuracy: 0.9600 - val_loss: 0.2768 - val_accuracy: 0.9189\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2053 - accuracy: 0.9467 - val_loss: 0.2729 - val_accuracy: 0.9459\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2040 - accuracy: 0.9467 - val_loss: 0.2699 - val_accuracy: 0.9459\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2028 - accuracy: 0.9467 - val_loss: 0.2657 - val_accuracy: 0.9459\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2021 - accuracy: 0.9467 - val_loss: 0.2610 - val_accuracy: 0.9459\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2012 - accuracy: 0.9467 - val_loss: 0.2587 - val_accuracy: 0.9459\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2004 - accuracy: 0.9467 - val_loss: 0.2584 - val_accuracy: 0.9459\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1992 - accuracy: 0.9467 - val_loss: 0.2598 - val_accuracy: 0.9459\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1976 - accuracy: 0.9467 - val_loss: 0.2623 - val_accuracy: 0.9459\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1964 - accuracy: 0.9467 - val_loss: 0.2668 - val_accuracy: 0.9189\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1958 - accuracy: 0.9467 - val_loss: 0.2697 - val_accuracy: 0.9189\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1949 - accuracy: 0.9467 - val_loss: 0.2688 - val_accuracy: 0.9189\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1937 - accuracy: 0.9467 - val_loss: 0.2654 - val_accuracy: 0.9189\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1926 - accuracy: 0.9467 - val_loss: 0.2628 - val_accuracy: 0.9189\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9467 - val_loss: 0.2617 - val_accuracy: 0.9189\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1905 - accuracy: 0.9467 - val_loss: 0.2601 - val_accuracy: 0.9459\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1892 - accuracy: 0.9467 - val_loss: 0.2564 - val_accuracy: 0.9459\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1882 - accuracy: 0.9467 - val_loss: 0.2520 - val_accuracy: 0.9459\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1879 - accuracy: 0.9467 - val_loss: 0.2487 - val_accuracy: 0.9459\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1868 - accuracy: 0.9467 - val_loss: 0.2471 - val_accuracy: 0.9459\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1859 - accuracy: 0.9467 - val_loss: 0.2443 - val_accuracy: 0.9459\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1855 - accuracy: 0.9467 - val_loss: 0.2415 - val_accuracy: 0.9459\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1848 - accuracy: 0.9467 - val_loss: 0.2396 - val_accuracy: 0.9459\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9467 - val_loss: 0.2377 - val_accuracy: 0.9459\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1837 - accuracy: 0.9467 - val_loss: 0.2364 - val_accuracy: 0.9459\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1830 - accuracy: 0.9467 - val_loss: 0.2353 - val_accuracy: 0.9459\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1821 - accuracy: 0.9467 - val_loss: 0.2339 - val_accuracy: 0.9730\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1814 - accuracy: 0.9467 - val_loss: 0.2332 - val_accuracy: 0.9730\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1803 - accuracy: 0.9467 - val_loss: 0.2332 - val_accuracy: 0.9459\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1793 - accuracy: 0.9467 - val_loss: 0.2335 - val_accuracy: 0.9459\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1779 - accuracy: 0.9467 - val_loss: 0.2329 - val_accuracy: 0.9459\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.9467 - val_loss: 0.2335 - val_accuracy: 0.9459\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1758 - accuracy: 0.9467 - val_loss: 0.2359 - val_accuracy: 0.9459\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1742 - accuracy: 0.9467 - val_loss: 0.2376 - val_accuracy: 0.9459\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1730 - accuracy: 0.9467 - val_loss: 0.2392 - val_accuracy: 0.9459\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1720 - accuracy: 0.9467 - val_loss: 0.2409 - val_accuracy: 0.9459\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9467 - val_loss: 0.2409 - val_accuracy: 0.9459\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1702 - accuracy: 0.9467 - val_loss: 0.2389 - val_accuracy: 0.9459\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1694 - accuracy: 0.9467 - val_loss: 0.2369 - val_accuracy: 0.9459\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1686 - accuracy: 0.9467 - val_loss: 0.2354 - val_accuracy: 0.9459\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1677 - accuracy: 0.9467 - val_loss: 0.2328 - val_accuracy: 0.9459\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1672 - accuracy: 0.9467 - val_loss: 0.2305 - val_accuracy: 0.9459\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1665 - accuracy: 0.9467 - val_loss: 0.2304 - val_accuracy: 0.9459\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1655 - accuracy: 0.9467 - val_loss: 0.2320 - val_accuracy: 0.9459\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.9467 - val_loss: 0.2342 - val_accuracy: 0.9459\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1634 - accuracy: 0.9467 - val_loss: 0.2373 - val_accuracy: 0.9189\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9600 - val_loss: 0.2387 - val_accuracy: 0.9189\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1623 - accuracy: 0.9600 - val_loss: 0.2372 - val_accuracy: 0.9189\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1614 - accuracy: 0.9600 - val_loss: 0.2365 - val_accuracy: 0.9189\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1607 - accuracy: 0.9600 - val_loss: 0.2356 - val_accuracy: 0.9189\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1599 - accuracy: 0.9600 - val_loss: 0.2345 - val_accuracy: 0.9189\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1592 - accuracy: 0.9600 - val_loss: 0.2337 - val_accuracy: 0.9189\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1584 - accuracy: 0.9600 - val_loss: 0.2329 - val_accuracy: 0.9189\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1577 - accuracy: 0.9600 - val_loss: 0.2319 - val_accuracy: 0.9189\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9600 - val_loss: 0.2309 - val_accuracy: 0.9189\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1562 - accuracy: 0.9600 - val_loss: 0.2318 - val_accuracy: 0.9189\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1556 - accuracy: 0.9600 - val_loss: 0.2331 - val_accuracy: 0.9189\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1552 - accuracy: 0.9600 - val_loss: 0.2318 - val_accuracy: 0.9189\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9600 - val_loss: 0.2279 - val_accuracy: 0.9189\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.9600 - val_loss: 0.2249 - val_accuracy: 0.9189\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1528 - accuracy: 0.9600 - val_loss: 0.2237 - val_accuracy: 0.9459\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9600 - val_loss: 0.2246 - val_accuracy: 0.9189\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1513 - accuracy: 0.9600 - val_loss: 0.2277 - val_accuracy: 0.9189\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1510 - accuracy: 0.9600 - val_loss: 0.2303 - val_accuracy: 0.9189\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9600 - val_loss: 0.2317 - val_accuracy: 0.9189\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1502 - accuracy: 0.9733 - val_loss: 0.2307 - val_accuracy: 0.9189\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1492 - accuracy: 0.9733 - val_loss: 0.2265 - val_accuracy: 0.9189\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1483 - accuracy: 0.9600 - val_loss: 0.2239 - val_accuracy: 0.9189\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1476 - accuracy: 0.9600 - val_loss: 0.2226 - val_accuracy: 0.9189\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1469 - accuracy: 0.9600 - val_loss: 0.2213 - val_accuracy: 0.9189\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1461 - accuracy: 0.9600 - val_loss: 0.2184 - val_accuracy: 0.9189\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1459 - accuracy: 0.9600 - val_loss: 0.2170 - val_accuracy: 0.9189\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9600 - val_loss: 0.2192 - val_accuracy: 0.9189\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1443 - accuracy: 0.9600 - val_loss: 0.2221 - val_accuracy: 0.9189\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1438 - accuracy: 0.9600 - val_loss: 0.2237 - val_accuracy: 0.9189\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1432 - accuracy: 0.9600 - val_loss: 0.2250 - val_accuracy: 0.9189\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9733 - val_loss: 0.2264 - val_accuracy: 0.9189\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1423 - accuracy: 0.9733 - val_loss: 0.2275 - val_accuracy: 0.9189\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1419 - accuracy: 0.9733 - val_loss: 0.2283 - val_accuracy: 0.9189\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1414 - accuracy: 0.9733 - val_loss: 0.2278 - val_accuracy: 0.9189\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1408 - accuracy: 0.9733 - val_loss: 0.2253 - val_accuracy: 0.9189\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1401 - accuracy: 0.9733 - val_loss: 0.2222 - val_accuracy: 0.9189\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1392 - accuracy: 0.9733 - val_loss: 0.2192 - val_accuracy: 0.9189\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1385 - accuracy: 0.9600 - val_loss: 0.2170 - val_accuracy: 0.9189\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1378 - accuracy: 0.9600 - val_loss: 0.2170 - val_accuracy: 0.9189\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1372 - accuracy: 0.9600 - val_loss: 0.2182 - val_accuracy: 0.9189\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9733 - val_loss: 0.2180 - val_accuracy: 0.9189\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9733 - val_loss: 0.2166 - val_accuracy: 0.9189\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1356 - accuracy: 0.9600 - val_loss: 0.2153 - val_accuracy: 0.9189\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1349 - accuracy: 0.9600 - val_loss: 0.2146 - val_accuracy: 0.9189\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1344 - accuracy: 0.9600 - val_loss: 0.2137 - val_accuracy: 0.9189\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 0.9600 - val_loss: 0.2134 - val_accuracy: 0.9189\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 0.9600 - val_loss: 0.2115 - val_accuracy: 0.9189\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1325 - accuracy: 0.9600 - val_loss: 0.2063 - val_accuracy: 0.9189\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "history = model.fit(X_train, Y_oh_train, validation_data=(X_val,Y_oh_val),batch_size= 64, epochs= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (cross-entropy and accuracy): [0.19205155968666077, 0.9736841917037964]\n",
      "\n",
      "Layer 0\n",
      "Bias:\n",
      " [ 0.04189947  0.6064683   0.65265673  0.46094602 -0.3419411 ]\n",
      "W:\n",
      " [[ 0.1124464  -0.64435554  0.7842609   1.0342042  -0.7266863 ]\n",
      " [ 0.39692333  0.7411584   0.6803319   0.43286636 -0.00585245]\n",
      " [ 1.150117    0.5508765  -0.7871595   0.5415498   0.6581558 ]\n",
      " [ 0.7424821  -0.88993347 -0.80744505  0.8321589   0.81578356]]\n",
      "\n",
      "Layer 1\n",
      "Bias:\n",
      " [-0.00600387 -0.10500789 -0.02902607  0.4701496   0.          0.23818853\n",
      " -0.26658744 -0.20536566 -0.18710484  0.24037994]\n",
      "W:\n",
      " [[ 0.47922987 -0.49463665 -0.15977626  0.1630968  -0.42624202  1.0278316\n",
      "   0.49563098  0.20037991  0.7317603   0.20221269]\n",
      " [-0.4004704   0.32293728 -0.09786278  1.3846078  -0.42246145 -0.82808346\n",
      "  -0.26129976 -0.6570575  -1.1452307  -0.40757957]\n",
      " [ 0.4811618   0.3911596   0.18869796  1.2462208  -0.16381973 -0.45223635\n",
      "   0.5502913  -0.9047097  -0.6226808  -0.8994972 ]\n",
      " [-0.6309521  -0.6885123  -0.11053745  0.4096367   0.00579995  0.4792393\n",
      "   0.4467139   0.2809568  -0.07024649  0.9712814 ]\n",
      " [-0.01863401 -0.40132147 -0.5250127  -0.7467435  -0.50261414 -0.36049992\n",
      "   0.8304531   0.14710794  0.70858544 -0.07145151]]\n",
      "\n",
      "Layer 2\n",
      "Bias:\n",
      " [ 0.28680992  0.10266462 -0.37503362]\n",
      "W:\n",
      " [[-0.47401592 -0.52287036  0.59745276]\n",
      " [-0.05333876  0.48270866  0.36970448]\n",
      " [-0.42211023  0.16937192  0.2798613 ]\n",
      " [ 1.1667229   0.36565337 -1.0366122 ]\n",
      " [ 0.3249457   0.43366683 -0.32666367]\n",
      " [-1.0693221   0.7642032   0.8059371 ]\n",
      " [ 0.18606322 -0.49314332  0.746748  ]\n",
      " [ 0.39114484 -0.8127577   1.1961699 ]\n",
      " [-0.17185557 -1.1087115   0.6400386 ]\n",
      " [-1.1353362   0.83000875  0.6108986 ]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, Y_oh_test, verbose=0)\n",
    "print('Test loss (cross-entropy and accuracy):',loss)\n",
    "print()\n",
    "W = model.get_weights()\n",
    "for ii in range(len(W)//2):\n",
    "    print(\"Layer %d\" %ii)\n",
    "    print('Bias:\\n', W[2*ii + 1])\n",
    "    print('W:\\n', W[2*ii])\n",
    "    print()\n",
    "\n",
    "plt.plot(history.history['loss'], label = \"Train loss\")\n",
    "plt.plot(history.history['val_loss'], label = \"Val loss\")\n",
    "plt.xlabel(\"Epoch (iteration)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label = \"Train accuarcy\")\n",
    "plt.plot(history.history['val_accuracy'], label = \"Val accuarcy\")\n",
    "plt.xlabel(\"Epoch (iteration)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References for creating this jupyter notebook \n",
    "\n",
    "1) https://keras.io/guides/functional_api/\n",
    "\n",
    "2) https://keras.io/api/models/sequential/\n",
    "\n",
    "3) https://keras.io/api/models/\n",
    "\n",
    "4) https://towardsdatascience.com/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks to Kashyap Patel who helped develop this tutorial!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
